## 高亮

	英文原文：https://www.elastic.co/guide/en/elasticsearch/reference/6.8/search-request-highlighting.html

	高亮器使你能够从搜索结果的一或多个字段中获取高亮的片段，以便向用户显示查询匹配的位置。
	当你发送高亮请求时，在响应中每个搜索结果会包含一个 highlight 元素，其中也包含高亮字段和高亮片段。
	
	注意：
	在提取要高亮的项（terms）时，高亮器不会反映查询的布尔逻辑。
	因此，对于一些复杂的布尔查询（例如，嵌套布尔查询、使用 minimun_should_match 的查询等等），可能会高亮与查询匹配不对应的部分文档。
	
	高亮需要字段的实际内容。如果该字段没有被存储（在 mapping 中，字段没有设置：store=true），
	则加载实际的 _source ，从 _source 中抽取相应的字段。
	
	注意：
	不能从 _source 中提取 _all 字段，因此只有在显示存储时才能用于高亮。
	
	例如，要使用默认的高亮器在每次搜索结果中为 cotent 字段获取高亮片段，请在指定 content 字段的请求体中包含一个 highlight 对象。
	
	GET /_search
	{
		"query" : {
			"match": { "content": "kimchy" }
		},
		"highlight" : {
			"fields" : {
				"content" : {}
			}
		}
	}
	
	Elasticsearch 支持三个高亮器：unified、plain、fvh（fast vector highlighter，快速矢量高亮器）。
	你可以为每个字段指定要使用的高亮器类型（type）。
	
## 统一高亮器（Unified highlighter）
	unified 高亮器使用 Lucene Unified 高亮器。它把文本拆分成句子，并使用 BM25 算法对单个句子进行打分，就像它们是语料库中的文档一样。
	它还支持精确短语和多词（multi-term）（模糊、前缀、正则）的高亮。它是默认高亮器。
	
## 普通高亮器（Plain highlighter）
	plain 高亮器使用标准的 Lucene 高亮器。它试图从理解词的重要性和短语查询中的任何词定位条件来反映查询匹配逻辑。
	
	警告：
	plain 高亮器最适合在单字段中高亮简单查询匹配项。
	为了准确地反映查询逻辑，它在内存中创建一个很小的索引库，并通过 Lucene 的查询执行计划器重新运行原始查询条件，以访问当前文档的低级匹配信息。
	对于需要高亮的每个字段和文档，都要重复此操作。
	如果你想要高亮具有复合查询的多个文档中的多个字段，我们建议在 postings 或 term_vector 字段上使用 unified 高亮器。
	
## 快速矢量高亮器（Fast vetor highlighter）
	
	fvh 高亮器使用 Lucene 快速矢量高亮器。它可以用于在 mapping 中把 term_vector 设置为 with_positions_offsets的字段。
	
	使用 boundary_scanner 定制。
	需要把 term_vector 设置为 with_positions_offsets，这会增加索引库的大小。
	可以将多个字段中的匹配项组合成为一个结果。查看 matched_fields
	可以为不同位置的匹配项分配不同的权重，允许在高亮增强查询时，将短语匹配排序在 term 匹配上方，从而增强短语匹配。
	
	警告：
	fvh 高亮器不支持跨度查询（span queries）。如果你需要对跨度查询的支持，请尝试另一种高亮器，例如：unified 高亮器。
	
## 偏移策略（Offsets Strategy）
	要根据查询的词创建有意义的搜索片段，高亮器需要知道原文中每个单词的起始和结束字符的偏移量。这些偏移量可以从以下位置获得：
	
	postings 列表
	如果在 mapping 中 index_options 被设置为 offsets，则 unified 高亮器无需再分析文本就能使用此信息来高亮文档。
	它直接再执行原先的查询，并从索引库中提取匹配的偏移，从而将集合限制在高亮的文档中。
	如果有大字段，这一点很重要，因为它不需要再分析待高亮的文本。相比于使用 term_vectors ,它只需要更少的磁盘空间。
	
	Term vectors
	如果在 mapping 中 把 term_vector 设置为 with_positions_offsets 来提供 term_vector 信息，则 unified 高亮器自动使用 term_vector 去高亮字段。
	它速度很快，特别是对于大字段（大于 1MB）和高亮多词查询（如前缀查询和通配符查询），因为它可以访问每个文档的 terms 词典。
	fvh 高亮器总是使用 term vectors。
	
	普通高亮（Plain highlighting）
	当没有其他选择时，unified 高亮器会使用此模式。
	它在内存中创建一个很小的索引库，并通过 Lucene 的查询执行计划器重新执行原始查询条件，以便访问当前文档的低级匹配信息。
	对于需要高亮的每个字段和文档，都要重复此操作。
	plain 高亮器总是使用普通高亮（plain highlighting）。
	
	警告：
	对于大文本来说，普通高亮需要大量的时间和内存。
	为了防止出现这种情况，在下一个主要的 Elastic 版本中，要分析的最大文本字符数被限制在 100万个。
	这个版本不能设置默认限制，但是，使用 index.highlight.max_analyzed_offset ,能为特定的索引库设置其值。
	没有为这个版本设置默认限制，但可以使用索引库设置 index.highlight.max_analyzed_offset ，为特定索引库设置默认限制。
	
	
## 高亮设置（Highlighting Settings）
	高亮设置可以在全局级别设置，也可以在字段级别覆盖。
	
	boundary_chars
	包含每一个边界字符的字符串。默认值：.,!? \t\n
	
	boundary_max_scan
	为了找到边界字符，要扫描的最大长度。默认值：20
	
	boundary_scanner
	指定如何拆分高亮片段：chars、sentence、word。这三个值只对 unified 和 fvh 高亮器有效。
	unified 高亮器对应的默认值是：sentence。fvh 高亮器对应的默认值是：chars
	
	chars
	使用 boundary_chars 指定的字符作为高亮的边界。boundary_max_scan 控制扫描边界字符的距离。
	仅对 fvh 高亮器有效。
	
	sentence
	在下一个句子边界上拆分高亮片段，如 Java 的 BreakIterator 所确定的。
	你可以指定要与 boundary_scanner_locale 一起使用的位置。
	
	注意：
	当与 unified 高亮器一起使用时，sentence 扫描器会在第一个单词边界处的 fragment_size 旁边拆分大于 fragment_size 的句子。
	你可以设置 fragment_size 为 0，这样就从不拆分任何句子。
	
	word
	在下一个单词边界处拆分高亮片段，如 Java 的 BreakIterator 所确定的。
	你可以指定要与 boundary_scanner_locale 一起使用的区域设置。
	
	
	boundary_scanner_locale
	控制用于语句搜索和单词边界的区域设置。这个参数采用语言标记的形式，例如，“en-US”、“fr-FR”、“ja-JP”。
	可以在区域设置语言标记（Locale Language Tag）文档中找到更多信息。默认值是：Locale.ROOT。
	
	encoder
	指明文本片段是否应当用 HTML 编码：default（无编码）、html（HTML 转义文本片段，然后插入到高亮标记中）。
	
	fields
	指定要检索高亮的字段。你可以使用通配符指定字段。
	例如，你可以指定 comment_* 来得到所有以 comment_ 开头的 text 和 keyword 字段。
	
	注意：
	使用通配符时仅高亮 text 和 keyword 字段。如果使用自定义映射器并想在任意字段上高亮，则必须显示地指定该字段名。
	
	force_source
	即使字段单独存储，也要根据源高亮。默认值为：false。
	
	fragmenter
	指定在高亮片段中如何拆分文本：simple 或 span。仅对 plain 高亮器有效。默认值是：span。
	
	simple
	把文本拆分为尺寸相同的片段。
	
	span
	把文本分隔成尺寸相同的片段，但会尽量避免在高亮词（terms）中间拆分文本。当你进行短语查询时，这比较有用。
	
	fragment_offset
	控制要开始高亮的边距。仅在使用 fvh 高亮器时有效。
	
	fragment_size
	以字符为单位的高亮片段的大小。默认为：100。
	
	highlight_query
	高亮搜索查询以外的查询匹配项。如果使用重新打分查询，这非常有用。因为默认情况下这些不会被高亮考虑。
	
	重要提示：
	Elasticsearch 不会校验 highligt_query 是否以任何方式包含搜索查询，因此可以定义它，从而不高亮合法的查询结果。
	通常，你应当把搜索结果作为 highlight_query 的一部分。
	
	matched_fields
	组合多个字段上的匹配项以高亮单个字段。对于用不同方式分析同一字符串的多字段来说，这是最直观的。
	所有 matched_fields 必须把 term_vector 设置为 with_positions_offsets，
	但只有匹配项组合到的字段才被加载，因此只有将 store 设置为 yes 时，字段才会受益。仅对 fvh 高亮器有效。
	
	no_match_size
	如果没有匹配到高亮片段，则要从字段开头返回的文本数量。默认值为：0（什么都不返回）。
	
	number_of_fragements
	要返回的最大片段数。如果片段数设置为 0，则不会返回任何片段。
	相反，整个字段内容都会高亮并返回。当你需要高亮短文本如标题、地址，并且不需要分段时，这很方便。
	如果 number_of_fragments 为 0，则将忽略 fragment_size。默认值为：5。
	
	order
	当设置为 score 时，按分数对高亮片段排序。默认情况下，片段会按照在字段（order：none）中出现的顺序输出。
	将此选项设置为 score，将首先输出最相关的片段。每个高亮器都会应用自己的逻辑来计算相关性分值。
	有关不同的高亮器如何找到最佳片段的更多细节，请查看文档“高亮器内在的工作机制”（How highlighters work internally）。
	
	phrase_limit
	控制要考虑的文档中匹配短语的数量。防止 fvh 高亮器分析太多短语和消费太多内存。
	当使用 matched_fields 时，每个匹配字段将考虑 phrase_limit 短语。
	提高限制会增加查询时间并消费更多内存。仅 fvh 高亮器支持。默认：256。
	
	pre_tags
	与 post_tags 一起使用，定义用于高亮文本的 HTML 标记。默认情况下，高亮文本被包装在 <em> 和 </em>标记中。指定为字符串数组。
	
	post_tags
	与 pre_tags 一起使用，定义用于高亮文本的 HTML 标记。默认情况下，高亮文本被包装在 <em> 和 </em>标记中。指定为字符串数组。
	
	require_field_match
	默认情况下，只高亮包含查询匹配项的字段。设置 require_field_match 为 false 以高亮所有字段。默认：true。
	
	tags_schema
	设置为 styled，以使用内建标记模式。styled 模式定义以下 pre_tags，并定义 post_tags 为 </em>。
	
	<em class="hlt1">, <em class="hlt2">, <em class="hlt3">,
	<em class="hlt4">, <em class="hlt5">, <em class="hlt6">,
	<em class="hlt7">, <em class="hlt8">, <em class="hlt9">,
	<em class="hlt10">
	
	type
	可用的高亮器：unified、plain、fvh。默认：unified。
	
	
## 高亮示例（Highlighting Examples）
	
### 覆盖全局设置（Override global settings）
	你可以全局地指定高亮器设置，并有选择地覆盖各个字段的高亮设置。
```
	GET /_search
	{
		"query" : {
			"match": { "user": "kimchy" }
		},
		"highlight" : {
			"number_of_fragments" : 3,
			"fragment_size" : 150,
			"fields" : {
				"_all" : { "pre_tags" : ["<em>"], "post_tags" : ["</em>"] },
				"blog.title" : { "number_of_fragments" : 0 },
				"blog.author" : { "number_of_fragments" : 0 },
				"blog.comment" : { "number_of_fragments" : 5, "order" : "score" }
			}
		}
	}
```
### 指定一个高亮查询（Specify a highlight query）
	你可以指定 highlight_query，以便在高亮时考虑其他信息。
	例如，下面的查询在 highlight_query 中同时包括搜索查询和再打分查询。若没有 highlight_query，高亮将只考虑搜索查询。
```
	GET /_search
	{
		"stored_fields": [ "_id" ],
		"query" : {
			"match": {
				"comment": {
					"query": "foo bar"
				}
			}
		},
		"rescore": {
			"window_size": 50,
			"query": {
				"rescore_query" : {
					"match_phrase": {
						"comment": {
							"query": "foo bar",
							"slop": 1
						}
					}
				},
				"rescore_query_weight" : 10
			}
		},
		"highlight" : {
			"order" : "score",
			"fields" : {
				"comment" : {
					"fragment_size" : 150,
					"number_of_fragments" : 3,
					"highlight_query": {
						"bool": {
							"must": {
								"match": {
									"comment": {
										"query": "foo bar"
									}
								}
							},
							"should": {
								"match_phrase": {
									"comment": {
										"query": "foo bar",
										"slop": 1,
										"boost": 10.0
									}
								}
							},
							"minimum_should_match": 0
						}
					}
				}
			}
		}
	}
```
### 设置高亮器类型（Set highlighter type）
	type 字段允许强制使用特定的高亮器类型。可用的值：unified、plain、fvh。
	以下是强制使用 plain 高亮器的例子：
```
	GET /_search
	{
		"query" : {
			"match": { "user": "kimchy" }
		},
		"highlight" : {
			"fields" : {
				"comment" : {"type" : "plain"}
			}
		}
	}
```
### 配置高亮标记（Configure highlighting tags）
	默认情况下，将高亮文本包装在 <em> 和 </em> 中。这可以通过设置 pre_tags 和 post_tags 来控制。例如：
```
	GET /_search
	{
		"query" : {
			"match": { "user": "kimchy" }
		},
		"highlight" : {
			"pre_tags" : ["<tag1>"],
			"post_tags" : ["</tag1>"],
			"fields" : {
				"_all" : {}
			}
		}
	}
```
	当使用 fast vector 高亮器时，你可以指定额外的标记，并按“重要性”排序。
```
	GET /_search
	{
		"query" : {
			"match": { "user": "kimchy" }
		},
		"highlight" : {
			"pre_tags" : ["<tag1>", "<tag2>"],
			"post_tags" : ["</tag1>", "</tag2>"],
			"fields" : {
				"_all" : {}
			}
		}
	}
```
	你还可以使用内置的 styled 标记模式：
```
	GET /_search
	{
		"query" : {
			"match": { "user": "kimchy" }
		},
		"highlight" : {
			"tags_schema" : "styled",
			"fields" : {
				"comment" : {}
			}
		}
	}
```
### 在源上高亮（Highlight on source）
	强制高亮显示基于源的字段，即使字段是单独存储的。默认：flase。
```
	GET /_search
	{
		"query" : {
			"match": { "user": "kimchy" }
		},
		"highlight" : {
			"fields" : {
				"comment" : {"force_source" : true}
			}
		}
	}
```
### 在多个字段上组合匹配项（Combine matches on multiple fields）
	
	警告：仅支持 fvh 高亮器。
	
	fvh 高亮器可以将多字段上的匹配组合来高亮单个字段。对于以不同方式分析同一字符串的多字段来说，这是最直观的。
	所有 matched_fields 都必须将 term_vector 设置为 with_positions_offsets，但只有匹配项组合到的字段才会被加载。
	因此只有该字段才会受益于将 store 设置为 yes。
	
	在下面的示例中，comment 字段被 english 分析器分析，comment.plain 字段被 standard 分析器分析。
```
	GET /_search
	{
		"query": {
			"query_string": {
				"query": "comment.plain:running scissors",
				"fields": ["comment"]
			}
		},
		"highlight": {
			"order": "score",
			"fields": {
				"comment": {
					"matched_fields": ["comment", "comment.plain"],
					"type" : "fvh"
				}
			}
		}
	}
```
	上面同时匹配“run with scissors” 和 “running with scissors”，高亮“running”和“scissors”，但不高亮“run”。
	如果这两个短语都出现在一个大文档中，那么“running with scissors”将在片段列表中的“run with scissors”上方排序，
	应为该片段中有更多的匹配项。
```
	GET /_search
	{
		"query": {
			"query_string": {
				"query": "running scissors",
				"fields": ["comment", "comment.plain^10"]
			}
		},
		"highlight": {
			"order": "score",
			"fields": {
				"comment": {
					"matched_fields": ["comment", "comment.plain"],
					"type" : "fvh"
				}
			}
		}
	}
```
	上面高亮了“run”、“running” 和 “scissors”，但由于 plain 匹配（“running”）被增强，所以仍会在“run with scissors”之上排序“running with scissors”。
```
	GET /_search
	{
		"query": {
			"query_string": {
				"query": "running scissors",
				"fields": ["comment", "comment.plain^10"]
			}
		},
		"highlight": {
			"order": "score",
			"fields": {
				"comment": {
					"matched_fields": ["comment.plain"],
					"type" : "fvh"
				}
			}
		}
	}
```
	上面的查询不会高亮“run”和“scissor”，但显示在匹配字段中不列出匹配项组合到的字段（comment）是很好的。
	
	注意：
	从技术上讲，也可以添加字段到与匹配项组合到字段不共享相同基础字符串的 matched_fields 中。
	结果可能没有多大意义，如果其中一个匹配项超出了文本的末尾，那么整个查询将失败。
	
	注意：
	设置 matched_fields 为非空数组时会有少量开销，因此始终首选。
```
	"highlight": {
        "fields": {
            "comment": {}
        }
    }
	将上面的改造为：
	"highlight": {
        "fields": {
            "comment": {
                "matched_fields": ["comment"],
                "type" : "fvh"
            }
        }
    }
```
### 显示排序高亮字段（Explicitly order highlighted fields）
	Elasticsearch 按照发送的顺序高亮字段，但根据 JSON 规范，对象是无序的。
	如果需要明确显示字段高亮的顺序，请将 fields 指定为数组。
	如果你需要显示指定顺序，
```
	GET /_search
	{
		"highlight": {
			"fields": [
				{ "title": {} },
				{ "text": {} }
			]
		}
	}
```
	Elasticsearch 中内置的高亮器都不关心字段高亮的顺序，但插件可能会。
	
	
### 控制高亮片段（Controll highlighted fragments）
	每个高亮字段都可以控制高亮片段的大小（以字符为单位，默认：100），以及要返回的最大片段数（默认：5）。例如：
```
	GET /_search
	{
		"query" : {
			"match": { "user": "kimchy" }
		},
		"highlight" : {
			"fields" : {
				"comment" : {"fragment_size" : 150, "number_of_fragments" : 3}
			}
		}
	}
```
	除此之外，还可以指定高亮片段需要按分数排序。
```
	GET /_search
	{
		"query" : {
			"match": { "user": "kimchy" }
		},
		"highlight" : {
			"order" : "score",
			"fields" : {
				"comment" : {"fragment_size" : 150, "number_of_fragments" : 3}
			}
		}
	}
```
	如果 number_of_fragments 设置为 0，则不会生成片段，而是返回字段的全部内容，当然，它会被高亮。
	如果短文本需要高亮且不分段，这是非常方便的。注意：fragment_size 在这种情况下会被忽略。
```
	GET /_search
	{
		"query" : {
			"match": { "user": "kimchy" }
		},
		"highlight" : {
			"fields" : {
				"_all" : {},
				"blog.title" : {"number_of_fragments" : 0}
			}
		}
	}
```
	当使用 fvh 高亮器的 fragment_offset 参数来控制高亮开始处的边距。
	
	如果没有要高亮的匹配片段，则默认不返回任何内容。
	相反，通过设置 no_match_size（默认：0）为你想要返回的文本长度，我们可以从字段开头返回一段文本。
	实际长度可能比指定的短或长，因为它试图在单词边界上中断。
```
	GET /_search
	{
		"query" : {
			"match": { "user": "kimchy" }
		},
		"highlight" : {
			"fields" : {
				"comment" : {
					"fragment_size" : 150,
					"number_of_fragments" : 3,
					"no_match_size": 150
				}
			}
		}
	}
```
### 使用发布列表高亮（Highlight using the postings list）
	
	下面是在索引库映射中设置 comment 字段的例子，以允许使用 postings 高亮。
```
	PUT /example
	{
	  "mappings": {
		"doc" : {
		  "properties": {
			"comment" : {
			  "type": "text",
			  "index_options" : "offsets"
			}
		  }
		}
	  }
	}
```
	下面是一个设置 comment 字段以允许使用 term_vectors 高亮（这将导致索引库变大）的示例：
```
	PUT /example
	{
	  "mappings": {
		"doc" : {
		  "properties": {
			"comment" : {
			  "type": "text",
			  "term_vector" : "with_positions_offsets"
			}
		  }
		}
	  }
	}
```
### 为 plain 高亮器指定一个段划分器（Specify a fragmenter for the plain highlighter）
	
	当你使用 plain 高亮器时，可以选择 simple 或 span 分段器：
	
	请求：
```
	GET twitter/_search
	{
		"query" : {
			"match_phrase": { "message": "number 1" }
		},
		"highlight" : {
			"fields" : {
				"message" : {
					"type": "plain",
					"fragment_size" : 15,
					"number_of_fragments" : 3,
					"fragmenter": "simple"
				}
			}
		}
	}
```
	响应：
```
	{
		...
		"hits": {
			"total": 1,
			"max_score": 1.601195,
			"hits": [
				{
					"_index": "twitter",
					"_type": "_doc",
					"_id": "1",
					"_score": 1.601195,
					"_source": {
						"user": "test",
						"message": "some message with the number 1",
						"date": "2009-11-15T14:12:12",
						"likes": 1
					},
					"highlight": {
						"message": [
							" with the <em>number</em>",
							" <em>1</em>"
						]
					}
				}
			]
		}
	}
```
	请求：
```	
	GET twitter/_search
	{
		"query" : {
			"match_phrase": { "message": "number 1" }
		},
		"highlight" : {
			"fields" : {
				"message" : {
					"type": "plain",
					"fragment_size" : 15,
					"number_of_fragments" : 3,
					"fragmenter": "span"
				}
			}
		}
	}
```
	响应：
```
	{
		...
		"hits": {
			"total": 1,
			"max_score": 1.601195,
			"hits": [
				{
					"_index": "twitter",
					"_type": "_doc",
					"_id": "1",
					"_score": 1.601195,
					"_source": {
						"user": "test",
						"message": "some message with the number 1",
						"date": "2009-11-15T14:12:12",
						"likes": 1
					},
					"highlight": {
						"message": [
							" with the <em>number</em> <em>1</em>"
						]
					}
				}
			]
		}
	}
```
	如果将 number_of_fragments 设置为 0，则使用 NullFragmenter，它根本不分隔文本。
	这对于高亮文档或字段整个内容很有用。
	
## 高亮器内部如何工作的（How highlighters work internally）
	
	对一个给定的查询和文本（文档字段的内容），高亮器的目标是找到最佳文本片段，
	并在找到的片段中高亮查询词（terms）。为此，高亮器需要解决几个问题：
	
### 如何将文本分成片段？
	相关设置：fragment_size, fragmenter, 高亮器的 type, boundary_chars, 
	boundary_max_scan, boundary_scanner, boundary_scanner_locale.
	
	plain 高亮器首先使用给定的分析器分析文本，然后从中创建 token 流。
	plain 高亮器使用一个非常简单的算法把 token 流分成片段。
	它循环遍历 token 流中的 terms，每当当前 term 的 end_offset 超过 fragment_size 乘以已创建的片段数量时，
	就会创建一个新片段。
	使用 span 分段器进行更多的计算，以避免在高亮的 terms 之间打断文本。
	但总的来说，仅通过 fragment_size 拆分文本，有些片段可能比较奇怪，例如：以标点符号开头。
	
	unified 或 fvh 高亮器更好地利用 Java 的 BreakIterator 把文本分解成片段。
	这可以确保片段是一个有效的句子，只要 fragment_size 允许。
	
### 如何找到最佳片段？
	
	相关设置：number_of_fragments。
	
	为了找到最好的、最相关的片段，高亮器需要对给定查询的每个片段进行评分。与给定查询相关的片段打分。
	目标是只对那些参与生成文档命中的 terms 进行评分。对于一些复杂的查询，这还在进行中。
	
	plain 高亮器从当前 token 流创建一个内存索引库，
	然后通过 Lucene 的查询执行计划器重新运行原始的查询条件，以访问当前文本的更低级匹配信息。
	对于更复杂的查询，原始查询将被转换为跨度查询，因为跨度查询可以更精准地处理短语。
	然后利用得到的低级匹配信息对每个片段进行评分。plain 高亮器的评分方法相当简单。
	每个片段有该片段中找到的唯一查询词（terms）的数量进行评分。
	单个 term 的分数等于其权值，默认：1。因此，默认情况下，包含一个唯一查询 term 的片段，它的分值是：1；
	包含 2 个唯一查询 term 的片段，它的分值是：2，以此类推。这些片段根据其分数排序，因此将先输出得分最高的片段。
	
	fvh 高亮器不需要分析文本并创建内存索引库，因为它使用之前已索引的文档 term 向量（vectors），并在其中查找与查询相对应的 terms。
	fvh 高亮器根据该片段中找到的查询 terms 的数量对每个片段进行评分。
	与 plain 高亮器相似，单个 term 的分数等于其权值。与 plain 高亮相比，所有查询 terms 都会计数，而不仅仅是唯一 terms。
	
	unified 高亮器可以使用预先索引的 term 向量（vectors）或 预先索引的 terms 偏移量（如果有的话）。
	否则，与 plain 高亮器类似，它必须从文本创建内存索引库。unified 高亮器使用 BM25 评分模型对片段进行评分。
	
	
### 在片段中，如何高亮查询词（terms）？
	
	相关设置：pre-tags、post-tags。
	
	目标是只高亮那些参与生成文档命中的 terms。对于有些复杂的布尔查询，工作仍在进行中，
	因为高亮器不会反映这个查询的布尔逻辑，只会提取叶子（terms、phrases、prefix 等等）查询。
	
	plain 高亮器给定 token 流和原始文本，重新编译原始文本来仅高亮上一步骤的低级匹配信息结构中包含的 token 流中的 terms。

	fvh 和 unified 高亮器使用中间数据结构以某种原始形式表示片段，然后用实际文本填充它们。
	
	高亮器使用 pre-tags、post-tags 来编码高亮的 terms。
	
	
### unified 高亮器工作的示例
	
	让我们更详细地了解 unified 高亮器如何工作的。
	
	首先，我们创建一个带有文本字段 content 的索引库，它将使用 english 分析器进行索引，并且将不使用 offsets 或 term vectors 进行索引。
```
	PUT test_index
	{
		"mappings": {
			"_doc": {
				"properties": {
					"content" : {
						"type" : "text",
						"analyzer" : "english"
					}
				}
			}
		}
	}
```
	我们将以下文档放入该索引库中：
```
	PUT test_index/_doc/doc1
	{
	  "content" : "For you I'm only a fox like a hundred thousand other foxes. But if you tame me, we'll need each other. You'll be the only boy in the world for me. I'll be the only fox in the world for you."
	}
```
	然后，我们执行下面的带一个高亮请求的查询：
```
	GET test_index/_search
	{
		"query": {
			"match_phrase" : {"content" : "only fox"}
		},
		"highlight": {
			"type" : "unified",
			"number_of_fragments" : 3,
			"fields": {
				"content": {}
			}
		}
	}
```
	在找到文档 doc1 作为查询结果后，这个结果将被传递给 unified 高亮器，以高亮这个文档的 content 字段。
	由于 content 字段没有 offset 或 term vectors 进行索引，因此将分析其原始字段值，并根据与查询匹配的 terms 构建内存索引库：
```
	{"token":"onli","start_offset":12,"end_offset":16,"position":3},
	{"token":"fox","start_offset":19,"end_offset":22,"position":5},
	{"token":"fox","start_offset":53,"end_offset":58,"position":11},
	{"token":"onli","start_offset":117,"end_offset":121,"position":24},
	{"token":"onli","start_offset":159,"end_offset":163,"position":34},
	{"token":"fox","start_offset":164,"end_offset":167,"position":35}
```
	复杂的短语查询将被转换为跨度查询：spanNear([text:onli, text:fox],0,true)，这意味着我们在彼此之间 0 距离内按给定顺序查找 terms：“onli:” 和 “fox”。
	跨度查询将针对之前创建的内存索引库运行，以查找以下匹配项：
```
	{"term":"onli", "start_offset":159, "end_offset":163},
	{"term":"fox", "start_offset":164, "end_offset":167}
```
	在我们的例子中，我们有一个匹配项，但也可能有几个匹配项。对于给定的匹配，unified 高亮器将字段文本分解为所谓的“短文本”。
	每个短文本必须至少包含一个匹配项。使用 Java 的 BreakIterator 的 unified 高亮器，
	确保每个短文本表示一个完整的句子，只要它不超过 fragment_size。
	对于我们的示例，我们得到了一个具有以下属性的单独短文本（此处只显示属性的子集）：
```
	Passage:
		startOffset: 147
		endOffset: 189
		score: 3.7158387
		matchStarts: [159, 164]
		matchEnds: [163, 167]
		numMatches: 2
```
	请注意：短文本如何使用适合于它的 BM25 评分公式计算分数。
	如果有比 number_of_fragments 更多的短文本可用，分数允许我们选择最好的评分短文本。
	如果请求时指定 order: "score"，则可根据分数排序短文本。
	
	最后，unified 高亮器将从字段的文本中提取与每个短文本对应的字符串：
```
	"I'll be the only fox in the world for you."
```
	利用短文本的 matchStarts 和 matchEnds 信息，并将用标记 <em> 和 </em> 格式化此字符串中的所有匹配项。
```
	I'll be the <em>only</em> <em>fox</em> in the world for you.
```
	这种格式化字符串是返回给用户的高亮器的最终结果。